{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw5_roc.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Homework 5 <br><br> Probability thresholds and the ROC curve </center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "In this part we will plot the ROC curve for a logistic regression classifier. We will also select probability thresholds for maximizing accuracy and minimizing cost. The problem is based on the \"Iris dataset\", which is provided with scikit-learn. You don't need to know anything about the dataset, but if you are curious you can find more information [here](https://en.wikipedia.org/wiki/Iris_flower_data_set) and [here](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "rng_seed = 23987\n",
    "cmap = ListedColormap(['red', 'green'])\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Load the data\n",
    "\n",
    "Begin by importing the data using `load_iris`. This returns a dictionary with several useful entries, including the feature and target data. The full dataset has 150 samples, with 4 features, and 3 classes of iris flower (the target). We will work with only two features (columns 1 and 2) and two classes (0 and 1). The code below removes the unwanted rows and columns from X and y. How many samples are left after filtering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "keeprows = [target in [1,2] for target in iris.target]\n",
    "X = iris.data[keeprows,:]\n",
    "y = LabelBinarizer().fit_transform(iris.target[keeprows])\n",
    "y = y[:,0]\n",
    "X = X[:,:2]\n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Split the data into training and testing\n",
    "\n",
    "Use `train_test_split` to split `X` and `y` into training and testing datasets. 20% of the data should be kept for testing. The `random_state` parameter of the splitter should be set to `rng_seed`, for autograding (and debugging) purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=rng_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Build a logistic regression pipeline\n",
    "\n",
    "Create a pipeline model with a standard scaler and a logistic regression classifier. Again, set the random state of the classifier to `rng_seed`. Then, train the model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('logreg', LogisticRegression(random_state=rng_seed))\n",
    "])\n",
    "\n",
    "model = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Extract theta0 and theta from the trained logistic regression model\n",
    "\n",
    "Extract the logistic regression coefficients -- theta0 and theta from the model. Remember that the logistic regression object is accessed with `model.named_steps['logreg']`. `theta0` should be a scalar, and theta should be an array of shape `(2,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "theta0 = model.named_steps['logreg'].intercept_[0] # TODO\n",
    "theta = model.named_steps['logreg'].coef_[0]\n",
    "theta0, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows the test data along with the linear decision boundary and its gradient (theta). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Xtest_scaled = model.named_steps['scaler'].transform(X_test)\n",
    "\n",
    "x2 = np.linspace(-3,3)\n",
    "x1 = -(theta0 + theta[1]*x2)/theta[0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.scatter(Xtest_scaled[:,0],Xtest_scaled[:,1],c=y_test,cmap=cmap)\n",
    "plt.plot(x1,x2)\n",
    "plt.arrow(0,0,theta[0],theta[1],head_width=.1)\n",
    "plt.axis('equal')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Compute the test accuracy\n",
    "\n",
    "Use the model to make predictions for the test data, and store those predictions in `yhat`. Then use scikit-learn's `accuracy_score` method to estimate the accuracy of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "yhat = model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5. Compute the prediction probabilities\n",
    "\n",
    "Use the model's `predict_proba` method to estimate class probabilities for the test data points. Notice that the probabilities for class 0 and class 1 add up to one for each test data point. Store the p(Y=1|X=x) in yhat_proba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_proba = model.predict_proba(X_test)\n",
    "yhat_proba = yhat_proba[:,1]\n",
    "yhat_proba[:3] # TODO: Not passing autograder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot below shows these probabilities in a 3D projection. You can rotate the figure with your mouse to get a sense of their relation to the decision boundary. Notice how the probabilties follow a sigmoid shape. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.scatter3D(Xtest_scaled[:,0],Xtest_scaled[:,1],yhat_proba,c=y_test,cmap=cmap)\n",
    "ax.plot(x1,x2,0*x1)\n",
    "ax.quiver(0,0,0, theta[0],theta[1],0, color='black')\n",
    "ax.set_xlim(-3,3)\n",
    "ax.set_ylim(-3,3)\n",
    "ax.set_xlabel('x0')\n",
    "ax.set_ylabel('x1')\n",
    "ax.set_zlabel('p(Y=1|X=x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Use scikit-learn to plot the ROC curve\n",
    "\n",
    "See the documentation on [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html) for the input and output parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, yhat) # TODO: Is this right?\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(fpr, tpr,'.-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Compute performance metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`N`, `Nn`, and `Np` are the number of test samples, the number of negative test samples, and the number of positive test samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(y_test)\n",
    "Nn = sum(y_test==0)\n",
    "Np = sum(y_test==1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allocate arrays arrays of length `N` for the true positive rate `TPR`, \n",
    "true negative rate `TNR`, the accuracy `A`, and the cost `Cost`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TPR = np.empty(N)\n",
    "TNR = np.empty(N)\n",
    "A = np.empty(N)\n",
    "Cost = np.empty(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Cost` will be computed assuming that a false positive is 5 times more costly than a false negative, and that there is zero profit associated with true positives and true negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaFP = 5\n",
    "alphaFN = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell sorts the probbility scores of the test samples from lowest to highest. That is, from least to most likely to belong to class 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rho = yhat_proba.copy()\n",
    "Rho.sort()\n",
    "Rho"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each probability threshold rho in Rho, compute the performance metrics (`TPR`, `TNR`, `A`, and `Cost`) with the decision boundary threshold set at rho. \n",
    "\n",
    "Use the formula:\n",
    "\n",
    "<div>\n",
    "<img src=\"formula.png\" width=\"250\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, rho in enumerate(Rho):\n",
    "    \n",
    "    # compute the positive and negative predictions using rho as the threshold\n",
    "    # Hint: You don't need to use the model for this. Only yhat_proba. \n",
    "    ypred = np.empty(N)\n",
    "    ...\n",
    "    ...\n",
    "\n",
    "    # Confusion matrix\n",
    "    TP = sum( (ypred==1) & (y_test==1) )\n",
    "    FP = sum( (ypred==1) & (y_test==0) )\n",
    "    TN = sum( (ypred==0) & (y_test==0) )\n",
    "    FN = sum( (ypred==0) & (y_test==1) )\n",
    "\n",
    "    # Performance metrics\n",
    "    TPR[i] = ...\n",
    "    TNR[i] = ...\n",
    "    A[i] = ...\n",
    "    Cost[i] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Best threshold for accuracy\n",
    "\n",
    "Report the optimal accuracy and its corresponding probability threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "rhoA = ...\n",
    "Abest = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Plot\n",
    "\n",
    "Plot the accuracy vs threshold curve and indicate the optimal point with a marker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "...\n",
    "plt.xlabel('rho',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Best threshold for cost\n",
    "\n",
    "Report the optimal cost and its corresponding probability threshold value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "...\n",
    "rhoC = ...\n",
    "Cbest = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Plot\n",
    "\n",
    "Plot the cost vs threshold curve and indicate the optimal point with a marker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "...\n",
    "plt.xlabel('rho',fontsize=16)\n",
    "plt.ylabel('Cost',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. ROC curve\n",
    "\n",
    "Plot the true positive rate vs the false positive rate. Use the same markers to indicate the optimal accuracy and optimal cost solutions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,5))\n",
    "...\n",
    "plt.xlabel('FPR',fontsize=16)\n",
    "plt.ylabel('TPR',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> y_test==[1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\narray([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\n        True,  True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(rhoC,0.5881078504748017,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(Cbest,11.0,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(theta0,-0.21835993602952442,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(test_acc,0.75)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(yhat_proba[:3],[0.70645249, 0.6714233 , 0.40515411],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(fpr[-3:],[0.66666667,1.,1.],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(tpr[:3],[0.,0.07142857, 0.21428571],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(thresholds[3:6],[0.75540295, 0.6714233 , 0.58810785],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(TPR[:3],[1.        , 0.92857143, 0.92857143],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(Cost[:3],[30., 31., 26.],atol=1e-3)\narray([ True,  True,  True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(rhoA,0.48578861517266614,1e-3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
