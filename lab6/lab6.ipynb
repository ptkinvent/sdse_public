{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab6.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 6 <br><br> Ensemble methods and hyperparameter tuning </center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this lab exercise we will apply several classification models to a problem in astrophysics. The problem is described [here](https://satyam5120.medium.com/predicting-a-pulsar-star-using-different-machine-learning-algorithms-d22ee8fc71b4) and [here](https://www.kaggle.com/datasets/colearninglounge/predicting-pulsar-starintermediate). It consists in labeling objects in space as pulsars or not pulsars, based on the properties of an integrated profile of observations and the DM-SNR curve. What these are exactly is not important to the data scientist. The given dataset has 8 feature columns:\n",
    "1. Mean of the integrated profile.\n",
    "2. Standard deviation of the integrated profile.\n",
    "3. Excess kurtosis of the integrated profile.\n",
    "4. Skewness of the integrated profile.\n",
    "5. Mean of the DM-SNR curve.\n",
    "6. Standard deviation of the DM-SNR curve.\n",
    "7. Excess kurtosis of the DM-SNR curve.\n",
    "8. Skewness of the DM-SNR curve.\n",
    "\n",
    "Our procedure will follow these steps:\n",
    "1. Load the data\n",
    "2. Remove incomplete samples\n",
    "3. Visual inspection of histograms, box plots, and correlation matrix\n",
    "4. Extracting the test dataset\n",
    "5. Hyperparameter tuning of of logistic regression with grid search\n",
    "6. Support vector machine\n",
    "7. Random forest\n",
    "8. AdaBoost\n",
    "9. Gradient Boosted Trees\n",
    "10. Final model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lab6_utils as lab6\n",
    "rng_seed = 2434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Load the data\n",
    "\n",
    "+ Load the data file `pulsar_data_train.csv` into a Pandas dataframe using [`pd.read_csv`](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html)\n",
    "+ Save the column headers corresponding to feature names to the variable `feature_names` ([Hint](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.columns.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = ...\n",
    "feature_names = ...\n",
    "D = len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Remove incomplete samples\n",
    "The image below is a visualization of [`df.isnull()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isnull.html). Notice that 3 of the features have a significant number of missing (null) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,14))\n",
    "sns.heatmap(df.isnull(),  cbar=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 Count null values\n",
    "\n",
    "Find the number of null values for each feature column of `df` (excluding `target_class`). Store the null counts in the provided dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "null_counts = dict().fromkeys(feature_names)\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 Remove rows with null values\n",
    "\n",
    "Remove all rows from the data frame that contain null values ([Hint](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Class imbalance\n",
    "\n",
    "Find the number of data points in each of the two classes. Save the number of class 0 data and class 1 data to `N0` and `N1` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N0 = ...\n",
    "N1 = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting p(X)\n",
    "\n",
    "Here are two visualizations of the marginal distribution of each of the inputs. The one on the left is a histogram, created with seaborn's `histplot`. The one on the right is a box or whisker plot, created with seaborn's `boxplot`. See [here](https://en.wikipedia.org/wiki/Box_plot) for more information about this type of visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=D,ncols=2,  figsize=(15, 40))\n",
    "for i in range(D):\n",
    "    feature = feature_names[i]\n",
    "    plt.figure(figsize = (5, 5))\n",
    "    sns.histplot(x=df[feature], ax=axes[i][0])\n",
    "    sns.boxplot(x=df[feature], ax=axes[i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting p(X|Y)\n",
    "\n",
    "Below we see boxplots applied to the features conditioned on each of the target values (0 and 1). A feature whose two conditional distributions are well-separated will likely be a good feature for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for feature in feature_names:\n",
    "    plt.figure(figsize = (10, 5))\n",
    "    sns.boxplot(x='target_class', y=feature, data=df)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation matrix (X,Y)\n",
    "The next cell color-codes the correlation matrix of (X,Y).\n",
    "+ Which two features are most correlated with each other?\n",
    "+ Which features are most correlated with the output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 10))\n",
    "corr_mat = df.corr()\n",
    "sns.heatmap(corr_mat, xticklabels = corr_mat.columns, yticklabels = corr_mat.columns, annot=True, cmap=\"PiYG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Extracting the test dataset\n",
    "\n",
    "Split the dataset contained in `df` into trainging and testing parts, with 90% used for training and 10% for testing. Remember to set the `random_state` to `rng_seed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 5.1. Logistic Regression\n",
    "\n",
    "In this part we will use grid search to choose the values of the hyperparameters of a logistic regression pipeline. Begin by creating a pipeline with a `StandardScaler` followed by `LogisticRegression` classifier. Pass these parameters to the contructor of the logistic regression classifier:\n",
    "+ `solver`: `liblinear`\n",
    "+ `random_state`: `rng_seed`\n",
    "\n",
    "Then fit the model using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler' , ... ) ,\n",
    "    ('clf' , ... )\n",
    "])\n",
    "model.fit(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Hyperparameter tuning with grid search\n",
    "\n",
    "Run gridsearch (`GridSearchCV`) with 5-fold cross validation. The parameters to search over are:\n",
    "\n",
    "+ the regularization function ('l1' or 'l2'), and\n",
    "+ the value of C. C should take values np.logspace(-4, 4, 5).\n",
    "\n",
    "Note, for `GridSearchCV` to work with the pipeline, it has to set the parameters of the model using their string names. Within the pipeline, the parameters of the model are prefixed with `clf__`. Hence, to set the penalty of logistic regression to `l1` or `l2`, you must include key-value pair `clf__penalty : ['l1','l2']` in `param_grid`.\n",
    "\n",
    "Pass the following parameters to the `GridSearchCV` contructor.\n",
    "+ `scoring=['accuracy', 'precision','recall']`,\n",
    "+ `cv=5`,\n",
    "+ `refit='accuracy'`\n",
    "\n",
    "`lab6_utils.py` contains useful functions for unpacking and plotting the results of the grid search. Use the `unpack_gridsearch` method to extract useful information from the grid search solution. This method returns:\n",
    "1. A pandas dataframe with the cross-validated performance metrics for each point on the grid.\n",
    "2. A dictionary with the best-case hyperparameter values\n",
    "3. The classifier with best-case hyperparameters assigned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid_logreg = {\n",
    "    'clf__penalty' : ...,\n",
    "    'clf__C' : ...}\n",
    "\n",
    "grid = GridSearchCV(...)\n",
    "\n",
    "grid_result = grid.fit(..., ...)\n",
    "\n",
    "df_logreg, best_param_logreg, best_logreg = lab6.unpack_gridsearch(...)\n",
    "\n",
    "# Visualize with plot_grid (included in lab6_utils.py)\n",
    "lab6.plot_grid(df_logreg,param_grid_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Package it into a function\n",
    "\n",
    "Next we will repeat this process with several other classification models. To keep the code clean, I suggest you collect the steps into a single function. This function should receive as inputs:\n",
    "1. The classifier object, e.g. `LogisticRegression(solver='liblinear',random_state=rng_seed)`\n",
    "2. The `param_grid` dictionary that defines the search space for `GridSearchCV`.\n",
    "\n",
    "It should:\n",
    "1. Create the pipeline mode\n",
    "2. Construct the `GridSearchCV` object\n",
    "3. Run `fit` on the grid search object, using the training data (no need to pass the data in, it's global)\n",
    "4. Run `unpack_gridsearch` to obtain `df`, `best_params`, `best_clf`\n",
    "5. Plot the result with `lab6.plot_grid`\n",
    "6. `retun df_clf, best_param_clf, best_clf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_grid_plot(clf,param_grid):\n",
    "    model = Pipeline(...)\n",
    "\n",
    "    grid = GridSearchCV(...)\n",
    "\n",
    "    grid_result = grid.fit(...)\n",
    "\n",
    "    df_clf, best_param_clf, best_clf  = lab6.unpack_gridsearch(...)\n",
    "\n",
    "    lab6.plot_grid(...)\n",
    "\n",
    "    return df_clf, best_param_clf, best_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional models\n",
    "Next we will repeat this exercise for four additional model types: SVMs, Random forests, AdaBoost, and Gradient boosted trees. In each case, use the suggested parameter grid. **Remember to always set the random state for the model in its constructor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6. Support vector machine\n",
    "\n",
    "+ kernel: ['poly','rbf']\n",
    "+ C: np.logspace(-2, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.svm import SVC\n",
    "param_grid_svm = ...\n",
    "df_svc, best_param_svc, best_svc = build_grid_plot(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 7. Random forest\n",
    "\n",
    "+ max_features: ['sqrt','log2']\n",
    "+ n_estimators: np.linspace(2, 100, 5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid_rf = ...\n",
    "df_rf, best_param_rf, best_rf = build_grid_plot(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8. AdaBoost\n",
    "\n",
    "+ learning_rate: [0.01,0.1]\n",
    "+ n_estimators: np.linspace(10, 100, 5, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_grid_ab = ...\n",
    "df_ab, best_param_ab, best_ab = build_grid_plot(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Gradient Boosted Trees\n",
    "\n",
    "+ learning_rate: [0.1,1.0]\n",
    "+ n_estimators' : [50,75,100]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "param_grid_gbc = ...\n",
    "df_gbc, best_param_gbc, best_gbc = build_grid_plot(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10. Final model selection\n",
    "\n",
    "Choose the best classifier on the basis of the accuracy obtained in the grid search. Assign it to `my_best_clf`. Then compute the test accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "my_best_clf = ...\n",
    "ypred = my_best_clf.predict(Xtest)\n",
    "print(accuracy_score(ytest, ypred))\n",
    "print(precision_score(ytest, ypred))\n",
    "print(recall_score(ytest, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('sdse')",
   "language": "python",
   "name": "python399jvsc74a57bd03b8b5ce4b1bd0cdb09a48c826d4154f25cb98d27fcdd75ace86cf123225b5557"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> len(feature_names)==8\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q10": {
     "name": "q10",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> ypred = my_best_clf.predict(Xtest)\n>>> accuracy_score(ytest,ypred)>0.98 and precision_score(ytest,ypred)>0.95 and recall_score(ytest, ypred)>0.84\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p1": {
     "name": "q2p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> null_counts[' Excess kurtosis of the integrated profile'] == 1735\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2p2": {
     "name": "q2p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> df.shape==(9273,9)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N0==8423\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain.shape==Xtrain.shape\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5p1": {
     "name": "q5p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> model.named_steps['clf'].coef_.shape==(1,8)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> model.named_steps['clf'].intercept_.shape==(1,)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(model.named_steps['clf'].coef_[0][:2],[0.194729,\n...                                               0.038752],atol=1e-2)\narray([ True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(model.named_steps['clf'].intercept_,-3.921041,atol=1e-3)\narray([ True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5p2": {
     "name": "q5p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_param_logreg=={'C': 100.0, 'penalty': 'l1'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(df_logreg['l1'].loc[0.0001,'mean_test_accuracy'],0.9076093469143199,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_param_svc=={'C': 10.0, 'kernel': 'rbf'}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_param_rf=={'max_features': 'log2', 'n_estimators': 75}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8": {
     "name": "q8",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_param_ab== {'learning_rate': 0.01, 'n_estimators': 10}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q9": {
     "name": "q9",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> best_param_gbc=={'learning_rate': 0.1, 'n_estimators': 50}\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
