{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8848d6ec",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"lab5.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f66b4a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Lab 5 <br><br> Logistic regression and Performance metrics </center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dffc4a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Precision is ill-defined and being set to 0.0\")\n",
    "\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_score,recall_score, accuracy_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "rng_seed = 454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875a5042",
   "metadata": {},
   "source": [
    "Description of the lab assignment..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e86acb",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2aaf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sklearn.datasets.load_breast_cancer()\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bbcc99",
   "metadata": {},
   "source": [
    "# Put the data into a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3cfacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data['target']\n",
    "N = len(df['target'])\n",
    "del data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bb09f3",
   "metadata": {},
   "source": [
    "## Flip the target value\n",
    "\n",
    "The scikit-learn dataset encodes a benign tumor as a 1 and a malignant tumor as a 0. This confuses the language, so let's flip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb53f095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = 1-df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e816525",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42aed0",
   "metadata": {},
   "source": [
    "The pandas dataframe provides the `corr()` methods, which computes the correlation matrix. Good predictor variables are characterized by having a large correlation with the output, but small correlation with other predictors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d227601",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e0e469",
   "metadata": {},
   "source": [
    "Focus on the correlations with the target variable. Sort them from largest to smallest in absolute value. The ones at the top of the list are good candidates to include in our model. But maybe not, if for example the are highly correlated amongst each other. We will use Lasso regularization for feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0aac434",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()['target'].abs().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f885b07",
   "metadata": {},
   "source": [
    "# Training and testing data\n",
    "\n",
    "The first step is to split the dataset into training and test sets. We will reserve 20% of the data for testing.  The code below uses scikit-learn's `train_test_spit` method to generate training and testing datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e513d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.iloc[:,:-1],\n",
    "                                                df['target'], \n",
    "                                                test_size=0.2, \n",
    "                                                random_state=rng_seed )\n",
    "\n",
    "len(Xtrain), len(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217a54d9",
   "metadata": {},
   "source": [
    "# Train a logistic regression model\n",
    "\n",
    "Our first model will be based on the most highly correlated feature only: `worst concave points`. \n",
    "The following code creates a logistic regression object. To compute the coefficients of the model, we pass the training data to the `fit` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f4af44",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain1 = Xtrain[['worst concave points']]\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(Xtrain1,ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a39ce8",
   "metadata": {},
   "source": [
    "# 1. Compute the confusion matrix\n",
    "\n",
    "Our next step is to assess the performance of the model by building its confusion matrix. The can be done easily with scikit-learn's `confusion_matrix()` function. However here we will build it by hand. \n",
    "\n",
    "The `compute_confusion_matrix` takes as parameters the trained model, along with the training or testing data (`X` and `y`). \n",
    "\n",
    "It should return a dictionary with keys `{'TP', 'FP', 'TN', 'FN'}` corresponding to the true positives, false positives, true negatives, and false negatives obtained by predicting the response for `X` and comparing it to `y`.\n",
    "\n",
    "In our case a 'positive' outcome is `y==1` (a malignant tumor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce10a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(model,X,y):\n",
    "    cm = dict.fromkeys({'TP', 'FP', 'TN', 'FN'})\n",
    "    ...\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b40a1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cm_train = compute_confusion_matrix(model,Xtrain1,ytrain)\n",
    "cm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052544cd",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eca6a6",
   "metadata": {},
   "source": [
    "# 2. Compute accuracy\n",
    "\n",
    "`compute_accuracy` takes a dictionary returned by `compute_confusion_matrix` and returns the scalar value of the accuracy, found with:\n",
    "\n",
    "$$ \\text{accuracy} = \\frac{TP+TN}{TP+TN+FP+FN} $$\n",
    "\n",
    "Use `compute_accuracy` to find the training and testing accuracy for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff617f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(cm):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76691f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "acc_train = compute_accuracy(cm_train)\n",
    "acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0e32a8",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef27a9",
   "metadata": {},
   "source": [
    "# 3. Compute precision and recall\n",
    "\n",
    "Repeat part 2 but for precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90e70b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_precision(cm):\n",
    "    ...\n",
    "\n",
    "def compute_recall(cm):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278a6c64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prn_train = compute_precision(cm_train)\n",
    "rcl_train = compute_recall(cm_train)\n",
    "\n",
    "prn_train, rcl_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431f8f5",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a770ee",
   "metadata": {},
   "source": [
    "# 4. L1 regularized logistic regression\n",
    "\n",
    "We now repeat the previous exercise, but instead of choosing the features by their correlation with the output, we will use the LASSO regularizer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f12ae5",
   "metadata": {},
   "source": [
    "## 4.1 Create a pipeline\n",
    "\n",
    "Scaling input features is a theoretical necesity for logistic regression. However it can be helpful for a) improving the numerical search and b) making comparisons amongst the trained coefficients. Use a `Pipeline` combine a `StandardScaler` with logistic regression. Use these hyperparameters for the logistic regression:\n",
    "\n",
    "``` python\n",
    "C=1\n",
    "penalty='l1'\n",
    "solver='liblinear'\n",
    "max_iter=1000\n",
    "random_state=rng_seed\n",
    "```\n",
    "\n",
    "Fit the model using the pipeline's `fit` method and using the full training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607ee0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "model = Pipeline(...)\n",
    "model.fit(...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5287c17b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a6e2a",
   "metadata": {},
   "source": [
    "## 4.2 Cross validation\n",
    "\n",
    "In the next part we will select features by sweeping over values of the regularization constant. We need a validation strategy for evaluating the performance of each level of regularization. We will use Use scikit-learn's `cross_validate` method for this. \n",
    "\n",
    "Read the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html) for an explanation of the input arguments. \n",
    "\n",
    "Then run `cross_validate` on the pipeline model we trained in the previous part. Use `cv=3` and record the accuracy, precision and recall by passing in `scoring=('accuracy','precision','recall')`.\n",
    "\n",
    "Save the mean of the three test metrics as `cv_acc`, `cv_prn`, and `cv_rcl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985bcc8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "scores = cross_validate(...)\n",
    "acc_cv = ...\n",
    "prn_cv = ...\n",
    "rcl_cv = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f52b22",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ae028",
   "metadata": {},
   "source": [
    "## 4.3 Sweep over the regularization weight\n",
    "\n",
    "We will now use the regularization parameter $\\lambda$ to shrink the coefficients. As we increase $\\lambda$ we should see the coefficients for the less useful features shrink to zero. In scikit-learn, the regularization parameter is called `C`, and is passed into the constructor for `LogisticRegression`. `C` actually equals  $1/\\lambda$, so increasing regularization strength (shrinking the parameters) corresponds to decreasing `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b22b540",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numCs = 40\n",
    "\n",
    "Cs = np.logspace(-3,2,numCs)\n",
    "D = Xtrain.shape[1]\n",
    "\n",
    "coefs = np.empty((numCs,D))\n",
    "\n",
    "# Initialize the performance arrays to `np.empty(numCs)`.\n",
    "acc_cv = ...\n",
    "prn_cv = ...\n",
    "rcl_cv = ...\n",
    "\n",
    "for c, C in enumerate(Cs):   \n",
    "    \n",
    "    print(c)\n",
    "    \n",
    "    # Create a fit a pipeline, as you did in the previous part.\n",
    "    ...\n",
    "    \n",
    "    # Extract the trained coefficients from the model and store them in the `coefs` array.\n",
    "    coefs[c,:] = model.named_steps['logreg'].coef_[0,:]\n",
    "    \n",
    "    # Use the same code from the previous part to compute cross-validation scores\n",
    "    scores = cross_validate(...)\n",
    "    acc_cv[c] = ...\n",
    "    prn_cv[c] = ...\n",
    "    rcl_cv[c] = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84288def",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2b1a0",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "The plot below should show that C=0.1 is amongst the lowest values that maximize the test performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f091022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,10),nrows=2)\n",
    "\n",
    "plt.subplot(211)\n",
    "plt.semilogx(Cs, acc_cv,'b--', label='cv acc')\n",
    "plt.semilogx(Cs, prn_cv,'m--', label='cv pre')\n",
    "plt.semilogx(Cs, rcl_cv,'g--', label='cv rec')\n",
    "plt.legend(fontsize=12)\n",
    "plt.ylim(0.8,1.02)\n",
    "plt.grid()\n",
    "plt.ylabel('performance',fontsize=16)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.semilogx(Cs, coefs)\n",
    "plt.ylim(-10,10)\n",
    "plt.grid()\n",
    "plt.ylabel('coefficients',fontsize=16)\n",
    "\n",
    "plt.xlabel('C',fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3476a7c8",
   "metadata": {},
   "source": [
    "# Final model\n",
    "\n",
    "The plot above shows that the best model occurs near C=0.1. We will take Cs[16]=0.11 to be the best value. Next, we sort and plot the absolute values of the coefficients for that model. Notice that only seven features have a non-zero coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cbd706",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C_ind = 16\n",
    "abs_coef = np.abs(coefs[best_C_ind,:])\n",
    "sorted_coeff_ind = np.argsort(abs_coef)\n",
    "\n",
    "plt.figure(figsize=(10,3))\n",
    "plt.stem(abs_coef[sorted_coeff_ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75a07b",
   "metadata": {},
   "source": [
    "Let's see which seven features were selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fc2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = np.array(df.columns[:-1])\n",
    "best_features = feature_names[sorted_coeff_ind[-1:-8:-1]]\n",
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f1a3ab",
   "metadata": {},
   "source": [
    "Suppose that we can only keep 4 features, perhaps because we are constrained by the time and cost of performing medical examinations. We select the top 4 for our final model.\n",
    "+ `worst radius`\n",
    "+ `worst concave points`\n",
    "+ `mean concave points`\n",
    "+ `worst texture`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd8eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_four_features = ['worst radius', 'worst concave points', 'mean concave points', 'worst texture']\n",
    "Xtrain2 = Xtrain[best_four_features]\n",
    "\n",
    "model = Pipeline([('scaler', StandardScaler()), \n",
    "                  ('logreg', LogisticRegression())])\n",
    "\n",
    "model.fit(Xtrain2,ytrain) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db73766",
   "metadata": {},
   "source": [
    "Finally, we calculate and report the test performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92e85b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest2 = Xtest[best_four_features]\n",
    "\n",
    "acc_test = accuracy_score(ytest,model.predict(Xtest2)) \n",
    "prn_test = precision_score(ytest,model.predict(Xtest2)) \n",
    "rcl_test = recall_score(ytest,model.predict(Xtest2)) \n",
    "acc_test, prn_test, rcl_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab14998c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc80939a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e318061",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('sdse')",
   "language": "python",
   "name": "python399jvsc74a57bd03b8b5ce4b1bd0cdb09a48c826d4154f25cb98d27fcdd75ace86cf123225b5557"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "otter": {
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> cm_train['FN'] == 98\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> cm_train['TP'] == 69\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(compute_accuracy({'TP': 1, 'TN': 2, 'FN': 4, 'FP': 8}),0.2,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(compute_precision({'TP': 1, 'TN': 2, 'FN': 4, 'FP': 8}),0.111111111,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(compute_recall({'TP': 1, 'TN': 2, 'FN': 4, 'FP': 8}),0.2,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p1": {
     "name": "q4p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(model.named_steps['scaler'].scale_[:4],[3.51492188,4.18884089,24.28804994,354.04182863],atol=1e-3)\narray([ True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(model.named_steps['scaler'].mean_[:4],[14.12329451,19.2083956,91.95894505,654.32087912],atol=1e-3)\narray([ True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(model.named_steps['logreg'].coef_[0,6],0.11256397924827233,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p2": {
     "name": "q4p2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(acc_cv,0.9626757290577438,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4p3": {
     "name": "q4p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(coefs[2,:5],[0., 0., 0., 0., 0.],atol=1e-2)\narray([ True,  True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(coefs[20,:5],[0., 0.03523389, 0., 0., 0.],atol=1e-2)\narray([ True,  True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> np.isclose(coefs[30,:5],[-3.51771003,0.,0.,0.,1.05151783],atol=1e-2)\narray([ True,  True,  True,  True,  True])",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
